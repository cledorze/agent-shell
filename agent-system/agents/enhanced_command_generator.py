import logging
import requests
import json
import os
import time
import traceback
import sys
from typing import List, Dict, Any

# Configure detailed logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/app/data/llm_debug.log')
    ]
)
logger = logging.getLogger(__name__)

class EnhancedCommandGenerator:
    """
    Command generator that uses Ollama to create Linux commands.
    """

    def __init__(self, knowledge_system_url=None):
        """
        Initialize the command generator with Ollama.

        Args:
            knowledge_system_url: URL of the knowledge system API
        """
        self.knowledge_system_url = knowledge_system_url or "http://knowledge-system:8084"

        # Ollama configuration
        self.ollama_host = os.environ.get('OLLAMA_HOST', '100.100.100.160')
        self.ollama_port = os.environ.get('OLLAMA_PORT', '11434')
        self.ollama_model = os.environ.get('OLLAMA_MODEL', 'ALIENTELLIGENCE/linuxcmdxpert')
        self.ollama_url = f"http://{self.ollama_host}:{self.ollama_port}/api/generate"

        logger.info(f"Ollama Command Generator initialized with host: {self.ollama_host}, model: {self.ollama_model}")

        # Test connectivity to Ollama
        self._test_connectivity()

    def _test_connectivity(self):
        """Test basic network connectivity to the Ollama API."""
        try:
            response = requests.get(f"http://{self.ollama_host}:{self.ollama_port}/api/version", timeout=5)
            logger.info(f"Connectivity test to Ollama API: Status {response.status_code}")
            if response.status_code == 200:
                version_info = response.json()
                logger.info(f"Ollama version: {version_info.get('version', 'unknown')}")
        except Exception as e:
            logger.error(f"Connectivity test to Ollama failed: {str(e)}")

    def generate_execution_plan(self, task: str) -> Dict[str, Any]:
        """
        Generate an execution plan by querying Ollama.

        Args:
            task: The task description

        Returns:
            Execution plan with commands from the LLM
        """
        logger.info(f"Generating commands for task: {task}")

        # Get relevant documentation to provide context
        docs = self.search_documentation(task)
        doc_context = self._format_documentation_context(docs)

        # Get commands from Ollama with detailed debugging
        try:
            commands = self._get_commands_from_ollama(task, doc_context)

            if commands:
                # Create execution plan with the generated commands
                return {
                    "task": task,
                    "steps": [
                        {
                            "name": "LLM-Generated Commands",
                            "description": f"Commands generated by LLM to accomplish: {task}",
                            "commands": commands,
                            "verification": "echo $?",
                            "requires_output_analysis": True
                        }
                    ],
                    "verification": commands[-1] if commands else "echo 'Task completed'"
                }

            # If command generation failed, return diagnostic information
            logger.error("Ollama command generation failed")
            return {
                "task": task,
                "steps": [
                    {
                        "name": "API Diagnostics",
                        "description": "Commands to display Ollama diagnostic information",
                        "commands": [
                            "echo 'Ollama API request failed. Check /app/data/llm_debug.log for details'",
                            f"curl -s http://{self.ollama_host}:{self.ollama_port}/api/version || echo 'Ollama connectivity failed'"
                        ],
                        "verification": "echo $?",
                        "requires_output_analysis": False
                    }
                ],
                "verification": "echo 'API diagnostics completed'"
            }

        except Exception as e:
            logger.error(f"Unexpected error in command generation: {str(e)}")
            logger.error(traceback.format_exc())

            # Return diagnostic commands
            return {
                "task": task,
                "steps": [
                    {
                        "name": "Error Diagnostics",
                        "description": "Error occurred during command generation",
                        "commands": [
                            f"echo 'Error during command generation: {str(e)}'",
                            "echo 'Check /app/data/llm_debug.log for complete details'"
                        ],
                        "verification": "echo $?",
                        "requires_output_analysis": False
                    }
                ],
                "verification": "echo 'Error diagnostics completed'"
            }

    def search_documentation(self, query: str, limit: int = 3) -> List[Dict[str, Any]]:
        """
        Search the knowledge system for relevant documentation.

        Args:
            query: Search query
            limit: Maximum number of results

        Returns:
            List of documentation items
        """
        try:
            response = requests.post(
                f"{self.knowledge_system_url}/search",
                json={"query": query, "limit": limit},
                timeout=5
            )
            response.raise_for_status()
            results = response.json().get("results", [])
            logger.info(f"Found {len(results)} documentation items for context")
            return results
        except Exception as e:
            logger.warning(f"Documentation search failed: {str(e)}")
            return []

    def _get_commands_from_ollama(self, task: str, doc_context: str) -> List[str]:
        """
        Get Linux commands from Ollama based on the task.

        Args:
            task: User's task description
            doc_context: Documentation context

        Returns:
            List of command strings
        """
        # Construct prompt for Ollama
        prompt = f"""You are a Linux system administration expert specializing in OpenSUSE Tumbleweed.
Your task is to generate the exact shell commands needed to accomplish a requested task.

Guidelines:
1. Return ONLY the commands, without explanations or markdown formatting
2. Focus on commands available on a standard OpenSUSE Tumbleweed installation
3. If multiple commands are needed, provide each one on a new line
4. Be precise and use the most appropriate tools for the job
5. Format your response as a JSON array of command strings: ["command1", "command2", ...]

Your commands will be executed directly on a production system, so ensure they are correct, efficient, and safe.

Task: {task}

Please generate the most appropriate Linux commands to accomplish this on OpenSUSE Tumbleweed.

{doc_context}"""

        logger.debug(f"Prompt length: {len(prompt)} characters")

        # Attempt to get commands from Ollama
        max_retries = 2
        for attempt in range(max_retries):
            try:
                logger.info(f"Sending request to Ollama API (attempt {attempt+1}/{max_retries})")

                payload = {
                    "model": self.ollama_model,
                    "prompt": prompt,
                    "stream": False  # We want the complete response at once
                }

                # Log the request details
                logger.debug(f"Request URL: {self.ollama_url}")
                logger.debug(f"Request model: {self.ollama_model}")

                # Use a longer timeout for the API call
                request_start_time = time.time()
                response = requests.post(
                    self.ollama_url,
                    json=payload,
                    timeout=30
                )
                request_duration = time.time() - request_start_time

                logger.debug(f"Request completed in {request_duration:.2f} seconds")
                logger.debug(f"Response status code: {response.status_code}")

                if response.status_code != 200:
                    error_message = f"Ollama API error: {response.status_code} - {response.text}"
                    logger.error(error_message)

                    if attempt < max_retries - 1:
                        logger.info(f"Retrying after API error (waiting 2 seconds)")
                        time.sleep(2)
                        continue
                    return []

                # Parse response (Ollama response format is different from OpenAI)
                result = response.json()
                logger.debug(f"Response JSON keys: {list(result.keys())}")

                # Extract the response text
                response_text = result.get("response", "")
                logger.debug(f"Ollama response: {response_text[:100]}...")

                # Extract commands from response
                commands = self._parse_llm_response(response_text)

                # Ensure commands are properly extracted from JSON if needed
                if commands and len(commands) == 1 and commands[0].startswith('[') and commands[0].endswith(']'):
                    try:
                        json_commands = json.loads(commands[0])
                        if isinstance(json_commands, list):
                            commands = json_commands
                            logger.info(f"Extracted {len(commands)} commands from JSON string")
                    except json.JSONDecodeError:
                        logger.warning("Failed to parse command as JSON array")

                if commands:
                    logger.info(f"Successfully generated {len(commands)} commands")
                    return commands
                else:
                    logger.warning("Failed to parse commands from Ollama response")
                    if attempt < max_retries - 1:
                        logger.info("Retrying after parsing failure")
                        time.sleep(1)

            except requests.exceptions.RequestException as e:
                error_message = f"Network error in Ollama request: {str(e)}"
                logger.error(error_message)

                # Additional diagnostic info for connection errors
                if isinstance(e, requests.exceptions.ConnectionError):
                    logger.error("Connection error details: This may indicate network connectivity issues or firewall restrictions")
                elif isinstance(e, requests.exceptions.Timeout):
                    logger.error("Timeout error: The request took too long to complete")

                if attempt < max_retries - 1:
                    logger.info(f"Retrying after network error (waiting 2 seconds)")
                    time.sleep(2)

            except Exception as e:
                logger.error(f"Unexpected error in Ollama request: {str(e)}")
                logger.error(traceback.format_exc())
                if attempt < max_retries - 1:
                    logger.info(f"Retrying after unexpected error (waiting 2 seconds)")
                    time.sleep(2)

        return []

    def _parse_llm_response(self, response: str) -> List[str]:
        """
        Parse the LLM response to extract commands.

        Args:
            response: LLM response text

        Returns:
            List of command strings
        """
        logger.debug(f"Parsing LLM response: {response[:100]}...")

        # Try to parse as JSON array first
        try:
            # Find JSON array in response
            if '[' in response and ']' in response:
                start_idx = response.find('[')
                end_idx = response.rfind(']') + 1
                json_str = response[start_idx:end_idx]

                logger.debug(f"Extracted JSON string: {json_str}")
                commands = json.loads(json_str)

                if isinstance(commands, list) and all(isinstance(cmd, str) for cmd in commands):
                    logger.debug(f"Successfully parsed JSON array with {len(commands)} commands")
                    return commands
                else:
                    logger.warning(f"Parsed JSON is not a list of strings: {type(commands)}")
        except json.JSONDecodeError as e:
            logger.debug(f"JSON parsing error: {str(e)}")

        # Fallback: extract commands line by line
        logger.debug("Falling back to line-by-line extraction")
        commands = []

        # Clean up response - remove markdown code blocks
        if "```" in response:
            logger.debug("Detected code blocks in response")
            parts = response.split("```")
            # Extract content from code blocks
            for i in range(1, len(parts), 2):
                if i < len(parts):
                    code_block = parts[i]
                    # Remove language identifier if present
                    if code_block and '\n' in code_block:
                        # Check if the first line looks like a language identifier
                        first_line = code_block.split('\n', 1)[0].strip()
                        if first_line and not first_line.startswith('#') and not any(char in first_line for char in [';', '|', '>', '<']):
                            code_block = code_block.split('\n', 1)[1]
                    lines = [line for line in code_block.strip().split('\n') if line.strip()]
                    logger.debug(f"Extracted {len(lines)} lines from code block")
                    commands.extend(lines)
        else:
            # Simple line-by-line extraction if no code blocks
            lines = [line.strip() for line in response.split('\n') if line.strip() and not line.strip().startswith('#')]
            logger.debug(f"Extracted {len(lines)} lines from plain text")
            commands.extend(lines)

        # Clean up commands (remove backticks, etc.)
        cleaned_commands = []
        for cmd in commands:
            # Remove backticks if present
            if cmd.startswith('`') and cmd.endswith('`'):
                cmd = cmd[1:-1]
            cleaned_commands.append(cmd)

        logger.debug(f"Final extracted commands: {cleaned_commands}")
        return cleaned_commands

    def _format_documentation_context(self, docs: List[Dict[str, Any]]) -> str:
        """
        Format documentation for inclusion in the prompt.

        Args:
            docs: Documentation items

        Returns:
            Formatted context string
        """
        if not docs:
            return "No specific documentation available."

        context = "Relevant documentation that may help:\n\n"

        for i, doc in enumerate(docs, 1):
            title = doc.get("title", "Untitled")
            content = doc.get("content", "")

            context += f"Document {i}: {title}\n"
            context += f"{content}\n\n"

        return context

